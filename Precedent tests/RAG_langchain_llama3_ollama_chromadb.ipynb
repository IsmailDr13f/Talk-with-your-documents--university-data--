{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9210864d-fada-499a-a08d-db8a5fc2ca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain\n",
    "#!pip install langchain_community\n",
    "#!pip install pdfminer.six\n",
    "#!pip install pillow_heif\n",
    "#!pip install opencv-python\n",
    "#!pip install pdf2image\n",
    "#!pip install unstructured_inference\n",
    "#!pip install pytesseract\n",
    "#!pip install pikepdf\n",
    "#!pip install unstructured_pytesseract\n",
    "#!pip install langchain-text-splitters\n",
    "#!pip install chromadb\n",
    "#!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc27975d-a6fd-4603-95cc-8fc4e7f636fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "os.environ['OCR_AGENT'] = 'unstructured.partition.utils.ocr_models.tesseract_ocr.OCRAgentTesseract'\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader,UnstructuredFileLoader,OnlinePDFLoader\n",
    "from pdfminer.pdfparser import PDFSyntaxError\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa670ae-7ccb-4a9e-bc13-97404457ff49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loader for text files\n",
    "loader = DirectoryLoader('documents/', glob=\"*.txt\", loader_cls=TextLoader, loader_kwargs={'encoding': 'UTF-8'})\n",
    "# Load documents\n",
    "documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9711e7ee-72b5-4959-95ae-8c61bf0ab52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Titre: 10ÈME ÉDITION DU CONCOURS FRANCOPHONE INTERNATIONAL «\\xa0MA THÈSE EN 180 SECONDES\\xa0», Date: janvier 10, 2024. Pour plus de détails, veuillez consulter le lien suivant : https://fstt.ac.ma/Portail2023/10eme-edition-du-concours-francophone-international-ma-these-en-180-secondes/', metadata={'source': 'documents\\\\10ÈME_ÉDITION_DU_CONCOURS_FRANCOPHONE_INTERNATIONAL_MA_THÈSE_EN_180_SECONDES.txt'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7addc842-d856-421d-9110-f81320abc6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9636eb4e-8044-477b-abc3-47123ec74c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████| 385/385 [13:45<00:00,  2.14s/it]\n"
     ]
    }
   ],
   "source": [
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks, \n",
    "    embedding=OllamaEmbeddings(model=\"nomic-embed-text\",show_progress=True,model_kwargs={\"device\": \"cuda\"}),\n",
    "    collection_name=\"txt_col\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b0fffaf-120e-4d58-bda5-0bb7f842f56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2534e941-89da-4f51-9df7-f2d80ab0a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM from Ollama\n",
    "local_model = \"llama3\"\n",
    "llm = ChatOllama(model=local_model,language = \"fr\",model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba7ed7c-c9fe-42aa-a79f-c4755c576412",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"Vous êtes un assistant modèle linguistique IA. Votre tâche consiste à générer deux\n",
    "    versions différentes de la question utilisateur donnée pour récupérer les documents pertinents d'une\n",
    "    base de données vectorielle. En générant plusieurs perspectives sur la question de l'utilisateur,\n",
    "    votre objectif est d'aider l'utilisateur à surmonter certaines des limitations de la recherche par similarité basée sur la distance.\n",
    "    Fournissez ces questions alternatives séparées par des nouvelles lignes.\n",
    "    Question originale : {question}\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51ac5a87-ac57-4040-86f4-9f52ada646ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(vector_db.as_retriever(), llm,prompt=QUERY_PROMPT)\n",
    "# RAG prompt\n",
    "\n",
    "template = \"\"\"Répondez à la question en français sur la base du contexte suivant :\n",
    "{context}\n",
    "\n",
    "Si la réponse à la question n'existe pas dans le contexte ci-dessus, veuillez indiquer que des informations supplémentaires sont nécessaires.\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c18fdeff-d119-4eea-a192-0bbac30e7116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|███████████████████████| 1/1 [00:05<00:00,  5.72s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████| 1/1 [00:02<00:00,  2.05s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████| 1/1 [00:02<00:00,  2.10s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████| 1/1 [00:02<00:00,  2.12s/it]\n",
      "OllamaEmbeddings: 100%|███████████████████████| 1/1 [00:02<00:00,  2.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selon le contexte, le coordinateur du Master en Sciences et Techniques (MST) : Sécurité IT et Big Data est le Pr.Abdelhamid ZOUHAIR. Son email est mstsit.bd@gmail.com.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"qui est le coordinateur de MST: intelligence artificielle et sciences des données ?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
