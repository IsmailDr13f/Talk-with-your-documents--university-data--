{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2178ec7-f3b2-4245-9f1e-c32f73fde0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain_community.document_loaders import UnstructuredPDFLoader,UnstructuredFileLoader,OnlinePDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1238159-54fe-4a9f-b5fa-14ace7dc3773",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import os\n",
    "\n",
    "# Lire les documents texte depuis un dossier\n",
    "def load_documents(folder_path):\n",
    "    documents = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(folder_path, filename), 'r', encoding='UTF-8') as file:\n",
    "                documents.append(file.read())\n",
    "    return documents\n",
    "\n",
    "folder_path = \"documents/\"\n",
    "documents = load_documents(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f2508c3-edf8-48d2-a7b7-7572959ce95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\drief\\AppData\\Roaming\\Python\\Python39\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "C:\\Users\\drief\\AppData\\Roaming\\Python\\Python39\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\drief\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Définir le modèle d'encodage\n",
    "embed_model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "embed_model = HuggingFaceEmbeddings(\n",
    "    model_name=embed_model_id,\n",
    "    model_kwargs={'device': device},\n",
    "    encode_kwargs={'device': device, 'batch_size': 32}\n",
    ")\n",
    "\n",
    "# Encoder les documents\n",
    "document_embeddings = embed_model.embed_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72913b6-1321-4ee7-a945-6b387df8233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "document_embeddings = np.array(document_embeddings)\n",
    "d = document_embeddings.shape[1]\n",
    "#print(d)  \n",
    "index = faiss.IndexFlatL2(d)\n",
    "document_embeddings = document_embeddings.astype('float32')\n",
    "index.add(document_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321f98ed-1a95-4d1d-a9bf-35e0d8de071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 298 avec distance 0.6787811517715454\n",
      "Filière: MST : Intelligence Artificielle et Sciences de Données\n",
      "\n",
      "Objectif: Cette formation d'excellence offre de solides connaissances en conception de systèmes d'intelligence artificielle et mathématiques appliquées afin de couvrir l'ensemble des problématiques de traitement et d'analyse des données massives que rencontre les entreprises. Elle met l'accent sur l'articulation entre apprentissage automatique, gestion et fouille de grandes masses de données, paradigmes du Big Data, représentation des connaissances, le traitement des données et sur les méthodologies récemment développées.\n",
      "\n",
      "Coordinateur: Pr.EZZIYYANI MOSTAFA\n",
      "Email: mezziyyani@uae.ac.ma\n",
      "\n",
      "Débouchés: \n",
      "\n",
      "Programme:\n",
      "Semestre 1:\n",
      "  1. THÉORIES ET SYSTÈMES DE RAISONNEMENTS INTELLIGENTS\n",
      "  2. MATHÉMATIQUES POUR ANALYSE DE DONNÉES\n",
      "  3. PROGRAMMATION AVANCÉE\n",
      "  4. BASES DE DONNÉES AVANCÉES\n",
      "  5. MACHINE LEARNING 1\n",
      "  6. ANGLAIS ET TECHNIQUE D’EXPRESSION\n",
      "\n",
      "Semestre 2:\n",
      "  1. INFRASTRUCTURE ET ARCHITECTURE DES SYSTÈMES DISTRIBUES & BIG DATA\n",
      "  2. PLATEFORMES IOT CORE: TECHNOLOGIES, DATA ET IA\n",
      "  3. METAHEURISTIQUES & ALGORITHMES DE RECHERCHE STOCHASTIQUE\n",
      "  4. SMA & NLP\n",
      "  5. DATAMING & BI\n",
      "  6. DEVELOPPEMENT PERSONNEL ET INTELLIGENCE EMOTIONNELL\n",
      "\n",
      "Semestre 3:\n",
      "  1. MULTIMEDIA MINING AND INDEXING\n",
      "  2. MACHINE LEARNING 2 : DEEP and TRANSFERT LEARNING\n",
      "  3. DATA SPACES & DATA  INTEGRATION & SEMANTIC INTEROPERABILITY\n",
      "  4. BLOCKCHAIN & SECURITE APPLICATIVE\n",
      "  5. VIRTUALIZATION, CLOUD AND EDGE COMPUTING\n",
      "  6. DIGITAL BUSINESS STRATEGIES  LEADERSHIP IN THE AGE OF AI\n",
      "\n",
      "Semestre 4:\n",
      "  1. Projet de fin d’étude\n",
      "\n",
      "\n",
      "Document 250 avec distance 0.9917184710502625\n",
      "Titre: LISTES DES CANDIDATS CONVOQUÉS À L’ORAL DE LA FILIÈRE INTELLIGENCE ARTIFICIELLE ET SCIENCES DE DONNÉES DU CYCLE MASTER, Date: octobre 3, 2023. Pour plus de détails, veuillez consulter le lien suivant : https://fstt.ac.ma/Portail2023/listes-des-candidats-convoques-a-loral-de-la-filiere-intelligence-artificielle-et-sciences-de-donnees-du-cycle-master/\n",
      "\n",
      "Document 292 avec distance 1.0075054168701172\n",
      "Filière: MST : Bases Cellulaires et Moléculaires en Biotechnologie\n",
      "\n",
      "Objectif: Le master BCMB vise la formation des spécialistes dans le domaine des Biotechnologies capables de répondre aux exigences de la recherche fondamentale et appliquée, et de s’adapter au marché de l’emploi dans les secteurs socio-économique et industriel. Le lauréat sera doté d’une nouvelle conception à la biologie alliant théorie à la pratique. A l’issu de cette formation, le lauréat sera capable d’élaborer des protocoles, de maîtriser la manipulation, de pouvoir analyser et exploiter les résultats expérimentaux obtenus. Il sera aussi capable d’innover en apportant des solutions dans le domaine des Biotechnologies, d’animer une équipe et de gérer des projets, de rédiger mémoires et articles scientifiques, rapports et présenter des exposés.L’objectif final est de former des chercheurs et des cadres de haut niveau, spécialistes en biotechnologies appliquées notamment dans les domaines de la sélection et l’amélioration génétique des plantes.\n",
      "\n",
      "Coordinateur: Pr.Mohamed NHIRI\n",
      "Email: mnhiri@uae.ac.ma\n",
      "\n",
      "Débouchés: Les lauréats ont la possibilité de continuer leurs études en formation doctorale, comme ils peuvent intégrer le monde de travail dans plusieurs secteurs publics et privés. Les profils et métiers visés par cette formation couvrent plusieurs secteurs publics, industriels et de service.Secteur public : chercheur, responsable, ingénieur dans des organismes dépendant de plusieurs ministères en particulier, du ministère de l’environnement, de l’agriculture et pêches maritimes, santé publique, éducation nationale et recherche scientifique ainsi que le ministère de l’intérieur.Industries : Ingénieur et chef d’équipe en industrie agroalimentaire, pharmaceutique, médicale et toute industrie ayant un pôle Biotechnologie.Service : poste de responsabilité dans les laboratoires publics ou privés d’analyse et de contrôle, organismes d’expertise, service vétérinaire et agricole, service de douanes, services spécialisés dans la gestion et le traitement des eaux, des déchets, bureaux d'études, hygiène et sécurité alimentaire, etc\n",
      "\n",
      "Programme:\n",
      "Semestre 1:\n",
      "  1. Techniques Expérimentales en Biotechnologie\n",
      "  2. Biologie Moléculaire\n",
      "  3. Technologie d’ADN recombinant\n",
      "  4. Communication cellulaire et voies de signalisation\n",
      "  5. BioInformatique\n",
      "  6. Du protocole expérimental à la rédaction scientifique\n",
      "\n",
      "Semestre 2:\n",
      "  1. Microbiologie Appliquée\n",
      "  2. Génomique\n",
      "  3. Concepts de Base en Génétique Quantitative\n",
      "  4. Protéomique\n",
      "  5. Technologie de transformation et de valorisation des bio-ressources\n",
      "  6. Système de Management intégré QSE\n",
      "\n",
      "Semestre 3:\n",
      "  1. - BA\n",
      "  2. Neurobiologie Cellulaire\n",
      "  3. Biologie de développement\n",
      "  4. Pathologies et génétique moléculaire\n",
      "  5. Techniques d’amélioration et de sélection chez les animaux\n",
      "  6. Thérapie Cellulaire et Génique\n",
      "  7. Kit Pour l’Emploi/ Projet professionnel\n",
      "\n",
      "Semestre 4:\n",
      "  1. Projet de fin d’étude\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encoder une requête\n",
    "query = \"C'est qui le coordinnateur de la MST: intelligence artificielle et sciences des données  ?\"\n",
    "query_embedding = embed_model.embed_query(query)\n",
    "\n",
    "# Convertir la requête en numpy array et s'assurer que c'est un tableau 2D\n",
    "query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
    "\n",
    "# Effectuer une recherche\n",
    "k = 3\n",
    "distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# Afficher les résultats\n",
    "for i in range(k):\n",
    "    print(f\"Document {indices[0][i]} avec distance {distances[0][i]}\")\n",
    "    print(documents[indices[0][i]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952c2cdf-ed20-4e13-bbb4-027ffad8c0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "class FAISSRetriever:\n",
    "    def __init__(self, index, documents):\n",
    "        self.index = index\n",
    "        self.documents = documents\n",
    "    \n",
    "    def retrieve(self, query_embedding, k=3):\n",
    "        query_embedding = np.array(query_embedding).astype('float32').reshape(1, -1)\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        return [(self.documents[i], distances[0][j]) for j, i in enumerate(indices[0])]\n",
    "\n",
    "# Charger un modèle de génération (par exemple, un modèle de la famille T5)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")\n",
    "model_ = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b49543-9572-48de-9fec-9c1f89fdc048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse générée: Cette formation d'excellence offre de solides connaissances en conception de systèmes d'intelligence artificielle et mathématiques appliquées afin de couvrir l'ensemble des problématiques de traitement et d'analyse des données que rencontrent les entreprises.\n"
     ]
    }
   ],
   "source": [
    "# Encoder une requête\n",
    "query = \"C'est qui le coordinnateur de la MST: intelligence artificielle et sciences des données  ?\"\n",
    "query_embedding = embed_model.embed_query(query)\n",
    "\n",
    "# Utiliser le retrieveur pour obtenir les documents les plus pertinents\n",
    "retriever = FAISSRetriever(index, documents)\n",
    "results = retriever.retrieve(query_embedding)\n",
    "\n",
    "# Préparer la requête et les documents contextuels pour la génération\n",
    "input_text = query + \" \" + \" \".join([doc for doc, dist in results])\n",
    "inputs = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=2000, truncation=True)\n",
    "\n",
    "# Générer la réponse\n",
    "outputs = model_.generate(inputs, max_length=1000, num_beams=2, early_stopping=True)\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Réponse générée:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da025075-c27a-4454-bab8-ad9e181d8833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14274199-fe75-451b-9644-ebfa9bc24d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab8d39b-4f41-474c-985d-1372fdf66097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f25b59d-b7a5-446c-bcca-926116bf7ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from torch import cuda, bfloat16\\nimport transformers\\nfrom accelerate import init_empty_weights, load_checkpoint_and_dispatch, disk_offload\\n\\nmodel_id = \"NousResearch/Llama-2-7b-chat-hf\"\\n\\n# Determine the device to use\\ndevice = f\\'cuda:{cuda.current_device()}\\' if cuda.is_available() else \\'cpu\\'\\n\\n# Set quantization configuration to load a large model with less GPU memory\\n# Requires the `bitsandbytes` library\\nbnb_config = transformers.BitsAndBytesConfig(\\n    load_in_4bit=True,\\n    bnb_4bit_quant_type=\\'nf4\\',\\n    bnb_4bit_use_double_quant=True,\\n    bnb_4bit_compute_dtype=bfloat16\\n)\\n\\n# HF authentication token\\nhf_auth = \\'HF_AUTH_TOKEN\\'\\n\\n# Initialize model configuration\\nmodel_config = transformers.AutoConfig.from_pretrained(\\n    model_id,\\n    use_auth_token=hf_auth\\n)\\n\\n# Load the model with weights\\nmodel = transformers.AutoModelForCausalLM.from_pretrained(\\n    model_id,\\n    trust_remote_code=True,\\n    config=model_config,\\n    quantization_config=bnb_config,\\n    token=hf_auth,\\n)\\n\\n# Define the device map\\ndevice_map = {\\n    \\'transformer.wte\\': \\'cpu\\',  \\n    \\'transformer.h\\': \\'cpu\\',    \\n    \\'lm_head\\': \\'cpu\\'           \\n}\\n\\n# Specify a directory for offloading\\noffload_dir = \\'C:/Users/drief/Desktop/NLP PROJECT/llama2\\'\\n\\n# Ensure the offload directory exists\\nimport os\\nif not os.path.exists(offload_dir):\\n    os.makedirs(offload_dir)\\n\\n# Use disk_offload to handle large model offloading\\ndisk_offload(\\n    model=model,\\n    offload_dir=offload_dir\\n)\\n\\nmodel.eval()\\nprint(f\"Model loaded and offloaded successfully\")\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from torch import cuda, bfloat16\n",
    "import transformers\n",
    "from accelerate import init_empty_weights, load_checkpoint_and_dispatch, disk_offload\n",
    "\n",
    "model_id = \"NousResearch/Llama-2-7b-chat-hf\"\n",
    "\n",
    "# Determine the device to use\n",
    "device = f'cuda:{cuda.current_device()}' if cuda.is_available() else 'cpu'\n",
    "\n",
    "# Set quantization configuration to load a large model with less GPU memory\n",
    "# Requires the `bitsandbytes` library\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type='nf4',\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=bfloat16\n",
    ")\n",
    "\n",
    "# HF authentication token\n",
    "hf_auth = 'HF_AUTH_TOKEN'\n",
    "\n",
    "# Initialize model configuration\n",
    "model_config = transformers.AutoConfig.from_pretrained(\n",
    "    model_id,\n",
    "    use_auth_token=hf_auth\n",
    ")\n",
    "\n",
    "# Load the model with weights\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    quantization_config=bnb_config,\n",
    "    token=hf_auth,\n",
    ")\n",
    "\n",
    "# Define the device map\n",
    "device_map = {\n",
    "    'transformer.wte': 'cpu',  \n",
    "    'transformer.h': 'cpu',    \n",
    "    'lm_head': 'cpu'           \n",
    "}\n",
    "\n",
    "# Specify a directory for offloading\n",
    "offload_dir = 'C:/Users/drief/Desktop/NLP PROJECT/llama2'\n",
    "\n",
    "# Ensure the offload directory exists\n",
    "import os\n",
    "if not os.path.exists(offload_dir):\n",
    "    os.makedirs(offload_dir)\n",
    "\n",
    "# Use disk_offload to handle large model offloading\n",
    "disk_offload(\n",
    "    model=model,\n",
    "    offload_dir=offload_dir\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "print(f\"Model loaded and offloaded successfully\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbf9172-89ae-4ace-b342-ea6a28c3a215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
